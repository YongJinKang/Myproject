{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "형태소 단위로 문장 분리\n",
      "----------------------\n",
      "['데이', '콘', '에서', '다양', '하', 'ㄴ', '컴피티션', '을', '즐기', '면서', '실력', '있', '는', '데이터', '분석가', '로', '성장', '하', '세요', '!!', '.']\n",
      " \n",
      "문장에서 명사 추출\n",
      "----------------------\n",
      "['데이', '데이콘', '콘', '다양', '컴피티션', '실력', '데이터', '분석가', '성장']\n",
      " \n",
      "품사 태킹(PoS)\n",
      "----------------------\n",
      "[('데이', 'NNG'), ('콘', 'NNG'), ('에서', 'JKM'), ('다양', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD'), ('컴피티션', 'UN'), ('을', 'JKO'), ('즐기', 'VV'), ('면서', 'ECE'), ('실력', 'NNG'), ('있', 'VV'), ('는', 'ETD'), ('데이터', 'NNG'), ('분석가', 'NNG'), ('로', 'JKM'), ('성장', 'NNG'), ('하', 'XSV'), ('세요', 'EFN'), ('!!', 'SW'), ('.', 'SF')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()\n",
    "\n",
    "sentence = '데이콘에서 다양한 컴피티션을 즐기면서 실력있는 데이터 분석가로 성장하세요!!.'\n",
    "\n",
    "print(\"형태소 단위로 문장 분리\")\n",
    "print(\"----------------------\")\n",
    "print(kkma.morphs(sentence))\n",
    "print(\" \")\n",
    "print(\"문장에서 명사 추출\")\n",
    "print(\"----------------------\")\n",
    "print(kkma.nouns(sentence))\n",
    "print(\" \")\n",
    "print(\"품사 태킹(PoS)\")\n",
    "print(\"----------------------\")\n",
    "print(kkma.pos(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "Okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "형태소 단위로 문장 분리\n",
      "----------------------\n",
      "['데', '이콘', '에서', '다양한', '컴피티션', '을', '즐기면서', '실력', '있는', '데이터', '분석', '가로', '성장하세요', '!!.']\n",
      " \n",
      "문장에서 명사 추출\n",
      "----------------------\n",
      "['데', '이콘', '컴피티션', '실력', '데이터', '분석', '가로']\n",
      " \n",
      "품사 태킹(PoS)\n",
      "----------------------\n",
      "[('데', 'Noun'), ('이콘', 'Noun'), ('에서', 'Josa'), ('다양한', 'Adjective'), ('컴피티션', 'Noun'), ('을', 'Josa'), ('즐기면서', 'Verb'), ('실력', 'Noun'), ('있는', 'Adjective'), ('데이터', 'Noun'), ('분석', 'Noun'), ('가로', 'Noun'), ('성장하세요', 'Adjective'), ('!!.', 'Punctuation')]\n"
     ]
    }
   ],
   "source": [
    "sentence = '데이콘에서 다양한 컴피티션을 즐기면서 실력있는 데이터 분석가로 성장하세요!!.'\n",
    "\n",
    "print(\"형태소 단위로 문장 분리\")\n",
    "print(\"----------------------\")\n",
    "print(Okt.morphs(sentence))\n",
    "print(\" \")\n",
    "print(\"문장에서 명사 추출\")\n",
    "print(\"----------------------\")\n",
    "print(Okt.nouns(sentence))\n",
    "print(\" \")\n",
    "print(\"품사 태킹(PoS)\")\n",
    "print(\"----------------------\")\n",
    "print(Okt.pos(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "품사 태킹(PoS)\n",
      "----------------------\n",
      "[('성장', 'NNG'), ('하', 'XSV'), ('었', 'EPT'), ('었', 'EPT'), ('다', 'EFN'), ('.', 'SF')]\n"
     ]
    }
   ],
   "source": [
    "kkma = Kkma()\n",
    "\n",
    "sentence = '성장했었다.'\n",
    "\n",
    "print(\"품사 태킹(PoS)\")\n",
    "print(\"----------------------\")\n",
    "print(kkma.pos(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "품사 태킹(PoS)\n",
      "----------------------\n",
      "[('성장', 'NNG'), ('하', 'XSV'), ('였', 'EPT'), ('었', 'EPT'), ('다', 'EFN'), ('.', 'SF')]\n"
     ]
    }
   ],
   "source": [
    "sentence = '성장하였었다.'\n",
    "\n",
    "print(\"품사 태킹(PoS)\")\n",
    "print(\"----------------------\")\n",
    "print(kkma.pos(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 불용어 제거(Stopwords removing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 불용어를 간단하게 정의내리면 문장에서 큰 의미가 없다고 생각되는 단어, 글자들 입니다. 불용어는 데이터와 문제에 따라 유동적입니다. 다음과 같은 예시를 생각해 보겠습니다.\n",
    "- 예시: \"이번에 새롭게 개봉한 영화의 배우들은 모두 훌륭한 연기력과 아름다운 목소리를 갖고 있어!!\"\n",
    "\n",
    "- 예시 문장에서 감성분석을 진행할 때는 \"훌륭한\"과 \"아름다운\"등이 주요 특징으로 사용될 것입니다. 하지만 경우에 따라서는 이러한 형용사들을 제외한 배우들의 연기력과 목소리라는 정보에 집중해야 할 때가 있습니다. 이럴때는 \"훌륭한\"과 \"아름다운\"은 불용어로 정의될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "tokenizer = Okt\n",
    "def text_preprocessing(text,tokenizer):\n",
    "    \n",
    "    stopwords = ['을', '를', '이', '가', '은', '는']\n",
    "    \n",
    "    txt = re.sub('[^가-힣a-z]', ' ', text)\n",
    "    token = tokenizer.morphs(txt)\n",
    "    token = [t for t in token if t not in stopwords]\n",
    "        \n",
    "    return token\n",
    "\n",
    "ex_text = \"이번에 새롭게 개봉한 영화의 배우들은 모두 훌륭한 연기력과 아름다운 목소리를 갖고 있어!!\"\n",
    "example_pre= text_preprocessing(ex_text,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['이번', '에', '새롭게', '개봉', '한', '영화', '의', '배우', '들', '모두', '훌륭한', '연기력', '과', '아름다운', '목소리', '갖고', '있어']\n"
     ]
    }
   ],
   "source": [
    "print(example_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 대회 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text_list):\n",
    "    \n",
    "    stopwords = ['을', '를', '이', '가', '은', '는', 'null'] #불용어 설정\n",
    "    tokenizer = Okt() #형태소 분석기 \n",
    "    token_list = []\n",
    "    \n",
    "    for text in text_list:\n",
    "        txt = re.sub('[^가-힣a-z]', ' ', text) #한글과 영어 소문자만 남기고 다른 글자 모두 제거\n",
    "        token = tokenizer.morphs(txt) #형태소 분석\n",
    "        token = [t for t in token if t not in stopwords or type(t) != float] #형태소 분석 결과 중 stopwords에 해당하지 않는 것만 추출\n",
    "        token_list.append(token)\n",
    "        \n",
    "    return token_list, tokenizer\n",
    "\n",
    "#형태소 분석기를 따로 저장한 이유는 후에 test 데이터 전처리를 진행할 때 이용해야 되기 때문입니다. \n",
    "train['new_article'], okt = text_preprocessing(train['content']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
